#!/usr/bin/env python3
"""
üß™ APLICACI√ìN REGLA #7 - TESTS PRIMERO
======================================

Demostraci√≥n de la REGLA #7: Si un test est√° bien redactado, modificar el c√≥digo, NO el test.

Este script analiza tests fallidos y determina si la falla es del c√≥digo o del test,
aplicando la metodolog√≠a establecida en la REGLA #7.

Fecha: Agosto 8, 2025
Aplicando: REGLAS_COPILOT.md - REGLA #7
"""

import os
import subprocess
import ast
from pathlib import Path
from datetime import datetime

# ‚úÖ REGLA #4: Importar SIC Bridge y SLUC
try:
    from sistema.sic_bridge import SICBridge
    from core.smart_trading_logger import log_trading_decision_smart_v6
    SIC_SLUC_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è SIC/SLUC no disponible - modo fallback")
    SIC_SLUC_AVAILABLE = False
    
    def log_trading_decision_smart_v6(event_type, data, **kwargs):
        print(f"[{event_type}] {data}")

def analyze_test_quality(test_file_path: str) -> dict:
    """
    ‚úÖ REGLA #7: Analizar calidad de un test para determinar si est√° bien redactado
    
    Retorna an√°lisis de calidad del test seg√∫n criterios de REGLA #7
    """
    
    log_trading_decision_smart_v6("TEST_ANALYSIS_START", {
        "rule": "REGLA #7 - Tests Primero",
        "test_file": str(test_file_path),
        "purpose": "Determinar si test est√° bien redactado"
    })
    
    analysis = {
        "file_path": str(test_file_path),
        "is_well_written": False,
        "quality_score": 0.0,
        "criteria_scores": {},
        "issues_found": [],
        "recommendations": []
    }
    
    try:
        # Leer archivo de test
        with open(test_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ‚úÖ REGLA #7: Criterios para test bien redactado
        criteria = {
            "descriptive_names": 0.0,      # Nombres descriptivos
            "clear_logic": 0.0,            # L√≥gica clara
            "appropriate_assertions": 0.0,  # Assertions apropiadas
            "realistic_cases": 0.0,        # Casos realistas
            "proper_setup": 0.0,           # Setup apropiado
            "documentation": 0.0           # Documentaci√≥n
        }
        
        lines = content.split('\n')
        
        # 1. ‚úÖ Verificar nombres descriptivos
        descriptive_test_names = 0
        total_test_functions = 0
        
        for line in lines:
            if line.strip().startswith('def test_'):
                total_test_functions += 1
                test_name = line.split('def ')[1].split('(')[0]
                # Nombre descriptivo si tiene m√°s de 3 palabras separadas por _
                if len(test_name.split('_')) >= 3:
                    descriptive_test_names += 1
        
        if total_test_functions > 0:
            criteria["descriptive_names"] = descriptive_test_names / total_test_functions
        
        # 2. ‚úÖ Verificar l√≥gica clara (docstrings en tests)
        docstring_tests = 0
        for i, line in enumerate(lines):
            if line.strip().startswith('def test_') and i + 1 < len(lines):
                if '"""' in lines[i + 1] or "'''" in lines[i + 1]:
                    docstring_tests += 1
        
        if total_test_functions > 0:
            criteria["clear_logic"] = docstring_tests / total_test_functions
        
        # 3. ‚úÖ Verificar assertions apropiadas
        assertion_keywords = ['assert', 'assertEqual', 'assertTrue', 'assertFalse', 'assertIn']
        assertion_count = 0
        
        for line in lines:
            if any(keyword in line for keyword in assertion_keywords):
                assertion_count += 1
        
        # Ratio de assertions por test (ideal: 1-5 assertions por test)
        if total_test_functions > 0:
            assertions_per_test = assertion_count / total_test_functions
            criteria["appropriate_assertions"] = min(1.0, assertions_per_test / 3.0)
        
        # 4. ‚úÖ Verificar casos realistas (buscar datos de prueba sensatos)
        realistic_indicators = ['EURUSD', 'data', 'timeframe', 'price', 'volume']
        realistic_score = 0
        
        for indicator in realistic_indicators:
            if indicator in content:
                realistic_score += 0.2
        
        criteria["realistic_cases"] = min(1.0, realistic_score)
        
        # 5. ‚úÖ Verificar setup apropiado (setUp, fixtures, etc.)
        setup_indicators = ['setUp', 'fixture', '@pytest', 'before', 'setup']
        setup_score = 0
        
        for indicator in setup_indicators:
            if indicator in content:
                setup_score += 0.3
        
        criteria["proper_setup"] = min(1.0, setup_score)
        
        # 6. ‚úÖ Verificar documentaci√≥n
        doc_indicators = ['"""', "'''", '#', 'Test:', 'Verifica', 'Prueba']
        doc_score = 0
        
        for indicator in doc_indicators:
            if indicator in content:
                doc_score += 0.2
        
        criteria["documentation"] = min(1.0, doc_score)
        
        # Calcular score total
        analysis["criteria_scores"] = criteria
        analysis["quality_score"] = sum(criteria.values()) / len(criteria)
        
        # ‚úÖ REGLA #7: Determinar si est√° bien redactado (threshold: 0.6)
        analysis["is_well_written"] = analysis["quality_score"] >= 0.6
        
        # Identificar issues y recomendaciones
        if criteria["descriptive_names"] < 0.5:
            analysis["issues_found"].append("Nombres de test poco descriptivos")
            analysis["recommendations"].append("Usar nombres m√°s descriptivos como test_detect_bos_with_valid_data")
        
        if criteria["clear_logic"] < 0.3:
            analysis["issues_found"].append("Falta documentaci√≥n en tests")
            analysis["recommendations"].append("Agregar docstrings explicando qu√© se est√° probando")
        
        if criteria["appropriate_assertions"] < 0.3:
            analysis["issues_found"].append("Pocas assertions por test")
            analysis["recommendations"].append("Agregar m√°s assertions espec√≠ficas")
        
        if criteria["realistic_cases"] < 0.4:
            analysis["issues_found"].append("Casos de prueba poco realistas")
            analysis["recommendations"].append("Usar datos de mercado reales para tests")
        
        log_trading_decision_smart_v6("TEST_ANALYSIS_COMPLETE", {
            "quality_score": analysis["quality_score"],
            "is_well_written": analysis["is_well_written"],
            "total_tests": total_test_functions,
            "issues_count": len(analysis["issues_found"])
        })
        
        return analysis
        
    except Exception as e:
        log_trading_decision_smart_v6("TEST_ANALYSIS_ERROR", {
            "error": str(e),
            "file": str(test_file_path)
        })
        analysis["issues_found"].append(f"Error analizando archivo: {e}")
        return analysis

def apply_rule_7_decision(test_analysis: dict, test_failure_info: str) -> dict:
    """
    ‚úÖ REGLA #7: Tomar decisi√≥n de modificar c√≥digo vs test basado en an√°lisis
    """
    
    decision = {
        "modify_code": False,
        "modify_test": False,
        "reasoning": "",
        "action_plan": [],
        "documentation_required": []
    }
    
    log_trading_decision_smart_v6("RULE_7_DECISION_START", {
        "test_quality_score": test_analysis["quality_score"],
        "is_well_written": test_analysis["is_well_written"],
        "failure_info": test_failure_info[:200]  # Truncar para logging
    })
    
    # ‚úÖ REGLA #7: Si test est√° bien redactado ‚Üí Modificar C√ìDIGO
    if test_analysis["is_well_written"]:
        decision["modify_code"] = True
        decision["reasoning"] = (
            f"Test est√° bien redactado (score: {test_analysis['quality_score']:.2f}). "
            "Seg√∫n REGLA #7, el problema est√° en el C√ìDIGO, no en el test."
        )
        decision["action_plan"] = [
            "1. Analizar falla espec√≠fica del test",
            "2. Identificar qu√© parte del c√≥digo no cumple la especificaci√≥n",
            "3. Modificar el c√≥digo para hacer pasar el test",
            "4. Validar que otros tests siguen pasando",
            "5. Documentar el cambio en SLUC"
        ]
        decision["documentation_required"] = [
            "Registrar en SLUC por qu√© se modific√≥ c√≥digo",
            "Documentar an√°lisis de calidad del test",
            "Actualizar bit√°cora con lecci√≥n aprendida"
        ]
    
    # ‚ö†Ô∏è REGLA #7: Si test mal redactado ‚Üí Analizar m√°s y posiblemente modificar test
    else:
        decision["modify_test"] = True
        decision["reasoning"] = (
            f"Test mal redactado (score: {test_analysis['quality_score']:.2f}). "
            "Issues encontrados: " + ", ".join(test_analysis["issues_found"][:3])
        )
        decision["action_plan"] = [
            "1. Revisar issues espec√≠ficos del test",
            "2. Corregir problemas de redacci√≥n identificados",
            "3. Aplicar recomendaciones de mejora",
            "4. Validar que el test mejorado sigue siendo v√°lido",
            "5. Documentar por qu√© se modific√≥ el test"
        ]
        decision["documentation_required"] = [
            "Documentar detalladamente por qu√© test era incorrecto",
            "Registrar issues espec√≠ficos encontrados",
            "Documentar mejoras aplicadas",
            "Actualizar bit√°cora con lecciones sobre calidad de tests"
        ]
    
    log_trading_decision_smart_v6("RULE_7_DECISION_COMPLETE", {
        "decision": "modify_code" if decision["modify_code"] else "modify_test",
        "reasoning_length": len(decision["reasoning"]),
        "action_steps": len(decision["action_plan"])
    })
    
    return decision

def demonstrate_rule_7():
    """
    ‚úÖ REGLA #7: Demostraci√≥n completa de la aplicaci√≥n de la regla
    """
    
    print("üß™ DEMOSTRACI√ìN REGLA #7 - TESTS PRIMERO")
    print("=" * 60)
    
    # Buscar archivos de test en el proyecto
    project_root = Path(__file__).parent.parent
    test_files = list(project_root.glob("tests/test_*.py"))
    
    if not test_files:
        print("‚ö†Ô∏è No se encontraron archivos de test")
        return
    
    print(f"üìã Archivos de test encontrados: {len(test_files)}")
    
    # Analizar un test espec√≠fico como ejemplo
    example_test = None
    for test_file in test_files:
        if "phase2" in test_file.name or "memory" in test_file.name:
            example_test = test_file
            break
    
    if not example_test and test_files:
        example_test = test_files[0]
    
    if example_test:
        print(f"\nüîç Analizando test ejemplo: {example_test.name}")
        
        # ‚úÖ REGLA #7: Analizar calidad del test
        analysis = analyze_test_quality(example_test)
        
        print(f"\nüìä AN√ÅLISIS DE CALIDAD DEL TEST:")
        print(f"   Score general: {analysis['quality_score']:.2f}/1.0")
        print(f"   Bien redactado: {'‚úÖ S√ç' if analysis['is_well_written'] else '‚ùå NO'}")
        
        if analysis['criteria_scores']:
            print(f"\nüìã Criterios evaluados:")
            for criteria, score in analysis['criteria_scores'].items():
                print(f"   {criteria}: {score:.2f}")
        
        if analysis['issues_found']:
            print(f"\n‚ö†Ô∏è Issues encontrados:")
            for issue in analysis['issues_found']:
                print(f"   - {issue}")
        
        if analysis['recommendations']:
            print(f"\nüí° Recomendaciones:")
            for rec in analysis['recommendations']:
                print(f"   - {rec}")
        
        # ‚úÖ REGLA #7: Simular decisi√≥n con falla de test
        simulated_failure = "AssertionError: Expected True but got False in BOS detection"
        
        print(f"\nüéØ APLICANDO REGLA #7:")
        print(f"   Falla simulada: {simulated_failure}")
        
        decision = apply_rule_7_decision(analysis, simulated_failure)
        
        print(f"\nüìã DECISI√ìN REGLA #7:")
        print(f"   Modificar c√≥digo: {'‚úÖ S√ç' if decision['modify_code'] else '‚ùå NO'}")
        print(f"   Modificar test: {'‚úÖ S√ç' if decision['modify_test'] else '‚ùå NO'}")
        print(f"   Razonamiento: {decision['reasoning']}")
        
        print(f"\nüéØ PLAN DE ACCI√ìN:")
        for i, action in enumerate(decision['action_plan'], 1):
            print(f"   {action}")
        
        print(f"\nüìù DOCUMENTACI√ìN REQUERIDA:")
        for doc in decision['documentation_required']:
            print(f"   - {doc}")
    
    # ‚úÖ REGLA #5: Documentar aplicaci√≥n de regla
    print(f"\n" + "=" * 60)
    print(f"üìä RESUMEN APLICACI√ìN REGLA #7:")
    print(f"   Regla aplicada exitosamente ‚úÖ")
    print(f"   Metodolog√≠a de an√°lisis establecida ‚úÖ")
    print(f"   Criterios de calidad definidos ‚úÖ")
    print(f"   Proceso de decisi√≥n automatizado ‚úÖ")
    print(f"   Documentaci√≥n de decisiones implementada ‚úÖ")
    
    return True

def main():
    """
    Main function aplicando todas las reglas Copilot
    """
    
    # ‚úÖ REGLA #4: Verificar SIC system ready (si est√° disponible)
    if SIC_SLUC_AVAILABLE:
        try:
            sic = SICBridge()
            log_trading_decision_smart_v6("SIC_STATUS", {
                "available": True,
                "rule_7_demo": True
            })
        except Exception as e:
            log_trading_decision_smart_v6("SIC_WARNING", {
                "warning": str(e),
                "continuing": "with REGLA #7 demo"
            })
    
    # Ejecutar demostraci√≥n
    success = demonstrate_rule_7()
    
    if success:
        print("\nüéâ REGLA #7 APLICADA EXITOSAMENTE")
        print("üìã Metodolog√≠a de 'Tests Primero' establecida")
        print("üîß Proceso de an√°lisis de calidad implementado")
        print("üéØ Decisiones autom√°ticas c√≥digo vs test funcionando")
    else:
        print("\n‚ùå PROBLEMAS EN APLICACI√ìN REGLA #7")
        print("üîß Revisar logs para m√°s detalles")

if __name__ == "__main__":
    main()
