#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ PATTERN DETECTOR CORE - ICT ENGINE v6.0 ENTERPRISE
====================================================

Detector avanzado de patterns ICT que implementa la metodolog√≠a institucional
para identificaci√≥n autom√°tica de:

üì¶ **Order Blocks ICT:**
- Bullish Order Blocks
- Bearish Order Blocks  
- Breaker Blocks
- Mitigation Blocks

üíé **Fair Value Gaps:**
- Bullish FVGs
- Bearish FVGs
- Premium FVGs
- Discount FVGs

üéØ **Caracter√≠sticas v6.0 Enterprise:**
- Integraci√≥n nativa con Market Structure Analyzer
- Cache predictivo de patterns
- An√°lisis multi-timeframe sincronizado
- Validaci√≥n de calidad enterprise
- Performance optimizada para real-time
- SIC v3.1 Enterprise integration

üîÑ **Pipeline Completo:**
1. Integraci√≥n con Market Structure Analyzer
2. Detecci√≥n de Order Blocks institucionales
3. Identificaci√≥n de Fair Value Gaps
4. An√°lisis de strength y probabilidad
5. Correlaci√≥n multi-timeframe
6. Validaci√≥n de calidad enterprise

Autor: ICT Engine v6.1.0 Enterprise Team
Versi√≥n: v6.1.0-enterprise
Fecha: Agosto 2025 - Fase 2.2 Cronograma
"""

# ===============================
# IMPORTS SIC v3.1 ENTERPRISE
# ===============================

import time
import threading
from typing import Dict, List, Optional, Any, Tuple, Union, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import numpy as np

# Imports SIC v3.1 Enterprise
try:
    from sistema.sic_v3_1.enterprise_interface import SICv31Enterprise
    from sistema.sic_v3_1.advanced_debug import AdvancedDebugger
    SIC_V3_1_AVAILABLE = True
except ImportError:
    SIC_V3_1_AVAILABLE = False
    # Fallback para desarrollo
    class SICv31Enterprise:
        def __init__(self): pass

# Sistema de logging
try:
    from sistema.sic import enviar_senal_log
    from core.smart_trading_logger import log_trading_decision_smart_v6
except ImportError:
    def enviar_senal_log(level, message, module, category):
        print(f"[{level}] {module}.{category}: {message}")
    def log_trading_decision_smart_v6(event_type, data, **kwargs):
        print(f"[{event_type}] {data}")

# Componentes ICT Engine v6.1.0
try:
    from core.analysis.market_structure_analyzer_v6 import MarketStructureAnalyzerV6, MarketStructureSignalV6
    from core.data_management.advanced_candle_downloader import AdvancedCandleDownloader
    from utils.mt5_data_manager import MT5DataManager
    MARKET_STRUCTURE_AVAILABLE = True
except ImportError:
    MARKET_STRUCTURE_AVAILABLE = False
    print("‚ö†Ô∏è Market Structure Analyzer no disponible")

# Sistema de Memoria Unificada v6.0 Enterprise (SIC + SLUC)
try:
    from core.analysis.unified_market_memory import (
        get_unified_market_memory,
        update_market_memory, 
        get_trading_insights
    )
    UNIFIED_MEMORY_AVAILABLE = True
    print("‚úÖ [SIC Integration] Sistema de Memoria Unificada v6.0 cargado")
except ImportError:
    UNIFIED_MEMORY_AVAILABLE = False
    print("‚ö†Ô∏è Sistema de Memoria Unificada no disponible")

# ‚úÖ FASE 2: Sistema de Memoria Unificada v6.1 Enterprise (FASE 2)
try:
    from core.analysis.unified_memory_system import (
        get_unified_memory_system,
        UnifiedMemorySystem
    )
    UNIFIED_MEMORY_SYSTEM_AVAILABLE = True
    print("‚úÖ [SIC Integration] UnifiedMemorySystem FASE 2 cargado")
except ImportError:
    UNIFIED_MEMORY_SYSTEM_AVAILABLE = False
    print("‚ö†Ô∏è UnifiedMemorySystem FASE 2 no disponible")

# ===============================
# TIPOS Y ENUMS ICT PATTERNS
# ===============================

class OrderBlockType(Enum):
    """üì¶ Tipos de Order Block ICT"""
    BULLISH_OB = "bullish_order_block"           # Order Block alcista
    BEARISH_OB = "bearish_order_block"           # Order Block bajista
    BREAKER_BLOCK = "breaker_block"              # Breaker Block
    MITIGATION_BLOCK = "mitigation_block"        # Mitigation Block
    REJECTION_BLOCK = "rejection_block"          # Rejection Block

class FVGType(Enum):
    """üíé Tipos de Fair Value Gap"""
    BULLISH_FVG = "bullish_fvg"                 # FVG alcista
    BEARISH_FVG = "bearish_fvg"                 # FVG bajista
    BALANCED_FVG = "balanced_fvg"               # FVG balanceado
    PREMIUM_FVG = "premium_fvg"                 # FVG en premium
    DISCOUNT_FVG = "discount_fvg"               # FVG en discount

class PatternStrength(Enum):
    """üí™ Fuerza del pattern"""
    WEAK = "weak"                               # D√©bil
    MODERATE = "moderate"                       # Moderado
    STRONG = "strong"                           # Fuerte
    VERY_STRONG = "very_strong"                 # Muy fuerte

class PatternStatus(Enum):
    """üîÑ Estado del pattern"""
    ACTIVE = "active"                           # Activo
    TESTED = "tested"                           # Testeado
    MITIGATED = "mitigated"                     # Mitigado
    INVALIDATED = "invalidated"                 # Invalidado

# ===============================
# DATACLASSES ICT PATTERNS
# ===============================

@dataclass
class OrderBlock:
    """üì¶ Order Block ICT detectado"""
    ob_type: OrderBlockType
    high_price: float
    low_price: float
    origin_candle_index: int
    origin_timestamp: datetime
    strength: PatternStrength
    status: PatternStatus
    probability: float
    
    # M√©tricas de calidad
    reaction_count: int = 0
    reaction_strength: float = 0.0
    volume_confirmation: bool = False
    structure_confluence: bool = False
    
    # Context informaci√≥n
    timeframe: str = ""
    symbol: str = ""
    narrative: str = ""
    
    # SIC v3.1 stats
    sic_stats: Dict[str, Any] = field(default_factory=dict)
    
    def get_middle_price(self) -> float:
        """üí´ Obtiene precio medio del Order Block"""
        return (self.high_price + self.low_price) / 2
    
    def get_size_pips(self) -> float:
        """üìè Obtiene tama√±o en pips (simplificado)"""
        return abs(self.high_price - self.low_price) * 10000

@dataclass
class FairValueGap:
    """üíé Fair Value Gap ICT detectado"""
    fvg_type: FVGType
    high_price: float
    low_price: float
    origin_candle_index: int
    origin_timestamp: datetime
    strength: PatternStrength
    status: PatternStatus
    probability: float
    
    # Estado de fill
    filled_percentage: float = 0.0
    is_filled: bool = False
    fill_timestamp: Optional[datetime] = None
    
    # M√©tricas de calidad
    gap_size_pips: float = 0.0
    volume_confirmation: bool = False
    structure_confluence: bool = False
    
    # Context informaci√≥n
    timeframe: str = ""
    symbol: str = ""
    narrative: str = ""
    
    # SIC v3.1 stats
    sic_stats: Dict[str, Any] = field(default_factory=dict)
    
    # ‚úÖ FASE 3: Multi-timeframe properties
    institutional_classification: str = ""
    memory_enhanced: bool = False
    h4_confluence: bool = False
    m15_alignment: bool = False
    m5_timing: bool = False
    
    def get_middle_price(self) -> float:
        """üí´ Obtiene precio medio del FVG"""
        return (self.high_price + self.low_price) / 2
    
    def get_gap_size(self) -> float:
        """üìè Obtiene tama√±o del gap"""
        return abs(self.high_price - self.low_price)

@dataclass
class PatternDetectionResult:
    """üéØ Resultado de detecci√≥n de patterns"""
    order_blocks: List[OrderBlock] = field(default_factory=list)
    fair_value_gaps: List[FairValueGap] = field(default_factory=list)
    detection_timestamp: datetime = field(default_factory=datetime.now)
    timeframe: str = ""
    symbol: str = ""
    total_patterns: int = 0
    quality_score: float = 0.0
    processing_time: float = 0.0
    
    # SIC v3.1 Enterprise stats
    sic_performance: Dict[str, Any] = field(default_factory=dict)

# ===============================
# PATTERN DETECTOR CORE
# ===============================

class ICTPatternDetector:
    """
    üéØ ICT PATTERN DETECTOR v6.0 ENTERPRISE
    =======================================
    
    Detector profesional de patterns ICT con:
    - Order Block detection avanzada
    - Fair Value Gap identification precisa
    - Pattern strength analysis
    - Quality validation enterprise
    - Multi-timeframe correlation
    - Integraci√≥n completa con SIC v3.1
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        üèóÔ∏è Inicializa el Pattern Detector v6.0
        
        Args:
            config: Configuraci√≥n avanzada del detector
        """
        
        # Configuraci√≥n v6.0
        self._config = config or {}
        self._enable_debug = self._config.get('enable_debug', True)
        self._use_multi_timeframe = self._config.get('use_multi_timeframe', True)
        self._enable_cache = self._config.get('enable_cache', True)
        
        # Configuraci√≥n de detecci√≥n
        self.min_ob_reaction_pips = self._config.get('min_ob_reaction_pips', 10.0)
        self.min_fvg_size_pips = self._config.get('min_fvg_size_pips', 5.0)
        self.pattern_lookback = self._config.get('pattern_lookback', 100)
        self.volume_weight = self._config.get('volume_weight', 0.3)
        self.structure_weight = self._config.get('structure_weight', 0.7)
        
        # Thresholds de calidad
        self.min_pattern_probability = self._config.get('min_pattern_probability', 60.0)
        self.min_pattern_strength = self._config.get('min_pattern_strength', 0.5)
        
        # Estado del detector
        self.detected_order_blocks: List[OrderBlock] = []
        self.detected_fvgs: List[FairValueGap] = []
        self.pattern_cache: Dict[str, Any] = {}
        self.performance_metrics: List[Dict[str, Any]] = []
        
        # Componentes
        self._market_structure: Optional[MarketStructureAnalyzerV6] = None
        self._downloader: Optional[AdvancedCandleDownloader] = None
        self._sic: Optional[SICv31Enterprise] = None
        self._unified_memory = None  # Sistema de Memoria Unificada v6.0 (FASE 1)
        self._unified_memory_system = None  # Sistema de Memoria Unificada v6.1 (FASE 2) (FASE 1)
        self._unified_memory_system = None  # Sistema de Memoria Unificada v6.1 (FASE 2)
        
        # Threading
        self._lock = threading.Lock()
        
        # Inicializar componentes
        self._initialize_components()
        
        # Log de inicializaci√≥n
        self._log_info("ICTPatternDetector v6.0 inicializado con SIC v3.1")
    
    def _initialize_components(self):
        """üîß Inicializa componentes v6.0"""
        try:
            # Configurar SIC v3.1 si est√° disponible
            if SIC_V3_1_AVAILABLE:
                self._sic = SICv31Enterprise()
                self._log_info("SIC v3.1 Enterprise integrado")
            
            # Configurar Sistema de Memoria Unificada v6.0 (SIC + SLUC)
            if UNIFIED_MEMORY_AVAILABLE:
                self._unified_memory = get_unified_market_memory()
                self._log_info("üß† Sistema de Memoria Unificada v6.0 conectado (SIC + SLUC)")
            
            # ‚úÖ FASE 2: Configurar UnifiedMemorySystem v6.1 (Trader Real)
            if UNIFIED_MEMORY_SYSTEM_AVAILABLE:
                self._unified_memory_system = get_unified_memory_system()
                self._log_info("üß† UnifiedMemorySystem v6.1 FASE 2 conectado (Trader Real)")
            
            # ‚úÖ FASE 2: Configurar UnifiedMemorySystem v6.1 (Trader Real)
            if UNIFIED_MEMORY_SYSTEM_AVAILABLE:
                self._unified_memory_system = get_unified_memory_system()
                self._log_info("üß† UnifiedMemorySystem v6.1 FASE 2 conectado (Trader Real)")
            
            # ‚úÖ FASE 2: Configurar UnifiedMemorySystem v6.1 (Trader Real)
            if UNIFIED_MEMORY_SYSTEM_AVAILABLE:
                self._unified_memory_system = get_unified_memory_system()
                self._log_info("üß† UnifiedMemorySystem v6.1 FASE 2 conectado (Trader Real)")
            
            # Configurar Market Structure Analyzer
            if MARKET_STRUCTURE_AVAILABLE:
                self._market_structure = MarketStructureAnalyzerV6()
                self._log_info("Market Structure Analyzer conectado")
            
            # Configurar Advanced Candle Downloader
            self._downloader = AdvancedCandleDownloader()
            self._log_info("AdvancedCandleDownloader conectado")
            
        except Exception as e:
            self._log_error(f"Error inicializando componentes: {e}")
    
    def detect_patterns(self, 
                       symbol: str, 
                       timeframe: str = "H1",
                       lookback_days: int = 7) -> PatternDetectionResult:
        """
        üéØ DETECCI√ìN COMPLETA DE PATTERNS ICT v6.0
        
        Args:
            symbol: S√≠mbolo a analizar (ej: "EURUSD")
            timeframe: Timeframe principal (ej: "H1")
            lookback_days: D√≠as de historia para an√°lisis
            
        Returns:
            PatternDetectionResult con todos los patterns detectados
        """
        start_time = time.time()
        
        try:
            self._log_info(f"üéØ Iniciando detecci√≥n de patterns: {symbol} {timeframe}")
            
            # 1. üì• OBTENER DATOS DE MERCADO
            candles_data = self._get_market_data(symbol, timeframe, lookback_days)
            if candles_data is None or len(candles_data) < 50:
                self._log_warning(f"Insuficientes datos para {symbol} {timeframe}")
                return self._create_empty_result(symbol, timeframe)
            
            # 2. üìä AN√ÅLISIS DE ESTRUCTURA (opcional)
            market_structure = None
            if self._market_structure:
                try:
                    market_structure = self._market_structure.analyze_market_structure(
                        candles_m15=candles_data,
                        current_price=float(candles_data['close'].iloc[-1]) if not candles_data.empty else 0.0,
                        symbol=symbol
                    )
                except Exception as e:
                    self._log_warning(f"Error en an√°lisis de estructura: {e}")
            
            # 3. üì¶ DETECTAR ORDER BLOCKS
            order_blocks = self._detect_order_blocks(candles_data, market_structure)
            
            # 4. üíé DETECTAR FAIR VALUE GAPS
            fair_value_gaps = self._detect_fair_value_gaps(candles_data, market_structure)
            
            # 5. üîç VALIDAR CALIDAD DE PATTERNS
            order_blocks = self._validate_pattern_quality(order_blocks, candles_data)
            fair_value_gaps = self._validate_pattern_quality(fair_value_gaps, candles_data)
            
            # 6. üìä CALCULAR STRENGTH Y PROBABILITY
            order_blocks = self._calculate_pattern_metrics(order_blocks, candles_data)
            fair_value_gaps = self._calculate_pattern_metrics(fair_value_gaps, candles_data)
            
            # 7. üéØ CREAR RESULTADO
            result = PatternDetectionResult(
                order_blocks=order_blocks,
                fair_value_gaps=fair_value_gaps,
                detection_timestamp=datetime.now(),
                timeframe=timeframe,
                symbol=symbol,
                total_patterns=len(order_blocks) + len(fair_value_gaps),
                quality_score=self._calculate_overall_quality(order_blocks, fair_value_gaps),
                processing_time=time.time() - start_time
            )
            
            # 8. üß† ACTUALIZAR MEMORIA UNIFICADA (SIC + SLUC)
            if self._unified_memory and UNIFIED_MEMORY_AVAILABLE:
                self._update_unified_memory_with_patterns(result, symbol, timeframe)
            
            # 9. üíæ ACTUALIZAR ESTADO
            self._update_detector_state(result)
            
            # 10. üìä M√âTRICAS DE PERFORMANCE
            self._update_performance_metrics(result)
            
            self._log_info(f"üéØ Patterns detectados: {result.total_patterns} "
                          f"(OB: {len(order_blocks)}, FVG: {len(fair_value_gaps)}) "
                          f"- Calidad: {result.quality_score:.1f}%")
            
            return result
            
        except Exception as e:
            self._log_error(f"Error en detecci√≥n de patterns: {e}")
            return self._create_empty_result(symbol, timeframe)
    
    def _detect_order_blocks(self, 
                           candles, 
                           market_structure: Optional[MarketStructureSignalV6] = None) -> List[OrderBlock]:
        """üì¶ Detecta Order Blocks ICT"""
        order_blocks = []
        
        try:
            if len(candles) < 20:
                return order_blocks
            
            # Detectar Order Blocks usando metodolog√≠a ICT
            for i in range(5, len(candles) - 5):
                # Obtener vela actual
                current_candle = candles.iloc[i]
                
                # 1. DETECTAR BULLISH ORDER BLOCK
                bullish_ob = self._detect_bullish_order_block(candles, i)
                if bullish_ob:
                    order_blocks.append(bullish_ob)
                
                # 2. DETECTAR BEARISH ORDER BLOCK
                bearish_ob = self._detect_bearish_order_block(candles, i)
                if bearish_ob:
                    order_blocks.append(bearish_ob)
                
                # 3. DETECTAR BREAKER BLOCKS
                breaker_block = self._detect_breaker_block(candles, i, market_structure)
                if breaker_block:
                    order_blocks.append(breaker_block)
            
            # Filtrar por calidad m√≠nima
            order_blocks = [ob for ob in order_blocks if ob.probability >= self.min_pattern_probability]
            
            self._log_debug(f"üì¶ Order Blocks detectados: {len(order_blocks)}")
            return order_blocks
            
        except Exception as e:
            self._log_error(f"Error detectando Order Blocks: {e}")
            return []
    
    def _detect_bullish_order_block(self, candles, candle_index: int) -> Optional[OrderBlock]:
        """üìà Detecta Bullish Order Block"""
        try:
            current = candles.iloc[candle_index]
            
            # Condici√≥n 1: Vela alcista fuerte
            if current['close'] <= current['open']:
                return None
            
            body_size = current['close'] - current['open']
            candle_range = current['high'] - current['low']
            
            # Condici√≥n 2: Body significativo
            if body_size < candle_range * 0.5:
                return None
            
            # Condici√≥n 3: Verificar reacci√≥n posterior
            reaction_strength = self._calculate_reaction_strength(candles, candle_index, 'bullish')
            
            if reaction_strength < self.min_ob_reaction_pips / 10000:  # Convertir pips
                return None
            
            # Crear Order Block
            order_block = OrderBlock(
                ob_type=OrderBlockType.BULLISH_OB,
                high_price=current['high'],
                low_price=current['low'],
                origin_candle_index=candle_index,
                origin_timestamp=current.name if hasattr(current.name, 'timestamp') else datetime.now(),
                strength=self._classify_pattern_strength(reaction_strength),
                status=PatternStatus.ACTIVE,
                probability=min(95.0, 60.0 + (reaction_strength * 1000)),
                reaction_strength=reaction_strength,
                narrative=f"Bullish Order Block - Reacci√≥n: {reaction_strength:.5f}"
            )
            
            return order_block
            
        except Exception as e:
            self._log_debug(f"Error detectando Bullish OB: {e}")
            return None
    
    def _detect_bearish_order_block(self, candles, candle_index: int) -> Optional[OrderBlock]:
        """üìâ Detecta Bearish Order Block"""
        try:
            current = candles.iloc[candle_index]
            
            # Condici√≥n 1: Vela bajista fuerte
            if current['close'] >= current['open']:
                return None
            
            body_size = current['open'] - current['close']
            candle_range = current['high'] - current['low']
            
            # Condici√≥n 2: Body significativo
            if body_size < candle_range * 0.5:
                return None
            
            # Condici√≥n 3: Verificar reacci√≥n posterior
            reaction_strength = self._calculate_reaction_strength(candles, candle_index, 'bearish')
            
            if reaction_strength < self.min_ob_reaction_pips / 10000:  # Convertir pips
                return None
            
            # Crear Order Block
            order_block = OrderBlock(
                ob_type=OrderBlockType.BEARISH_OB,
                high_price=current['high'],
                low_price=current['low'],
                origin_candle_index=candle_index,
                origin_timestamp=current.name if hasattr(current.name, 'timestamp') else datetime.now(),
                strength=self._classify_pattern_strength(reaction_strength),
                status=PatternStatus.ACTIVE,
                probability=min(95.0, 60.0 + (reaction_strength * 1000)),
                reaction_strength=reaction_strength,
                narrative=f"Bearish Order Block - Reacci√≥n: {reaction_strength:.5f}"
            )
            
            return order_block
            
        except Exception as e:
            self._log_debug(f"Error detectando Bearish OB: {e}")
            return None
    
    def _detect_breaker_block(self, 
                            candles, 
                            candle_index: int, 
                            market_structure: Optional[MarketStructureSignalV6] = None) -> Optional[OrderBlock]:
        """üí• Detecta Breaker Block (Order Block que se rompe y cambia de rol)"""
        try:
            # L√≥gica simplificada para Breaker Block
            # TODO: Implementar l√≥gica completa de Breaker Block
            
            current = candles.iloc[candle_index]
            
            # Verificar si hay cambio de estructura
            if not market_structure:
                return None
            
            # Placeholder para l√≥gica de Breaker Block
            # Se implementar√° en futuras versiones
            
            return None
            
        except Exception as e:
            self._log_debug(f"Error detectando Breaker Block: {e}")
            return None
    
    def _detect_fair_value_gaps(self, 
                              candles, 
                              market_structure: Optional[MarketStructureSignalV6] = None) -> List[FairValueGap]:
        """üíé Detecta Fair Value Gaps ICT"""
        fvgs = []
        
        try:
            if len(candles) < 3:
                return fvgs
            
            # Detectar FVGs usando metodolog√≠a ICT
            for i in range(1, len(candles) - 1):
                # 1. DETECTAR BULLISH FVG
                bullish_fvg = self._detect_bullish_fvg(candles, i)
                if bullish_fvg:
                    fvgs.append(bullish_fvg)
                
                # 2. DETECTAR BEARISH FVG
                bearish_fvg = self._detect_bearish_fvg(candles, i)
                if bearish_fvg:
                    fvgs.append(bearish_fvg)
            
            # Filtrar por tama√±o m√≠nimo
            fvgs = [fvg for fvg in fvgs if fvg.gap_size_pips >= self.min_fvg_size_pips]
            
            self._log_debug(f"üíé Fair Value Gaps detectados: {len(fvgs)}")
            return fvgs
            
        except Exception as e:
            self._log_error(f"Error detectando FVGs: {e}")
            return []
    
    def _detect_bullish_fvg(self, candles, candle_index: int) -> Optional[FairValueGap]:
        """üìà Detecta Bullish Fair Value Gap"""
        try:
            if candle_index < 1 or candle_index >= len(candles) - 1:
                return None
            
            prev_candle = candles.iloc[candle_index - 1]
            current_candle = candles.iloc[candle_index]
            next_candle = candles.iloc[candle_index + 1]
            
            # Condici√≥n: Gap entre low de next y high de prev
            if next_candle['low'] > prev_candle['high']:
                gap_size = next_candle['low'] - prev_candle['high']
                gap_size_pips = gap_size * 10000  # Conversi√≥n simplificada a pips
                
                if gap_size_pips >= self.min_fvg_size_pips:
                    fvg = FairValueGap(
                        fvg_type=FVGType.BULLISH_FVG,
                        high_price=next_candle['low'],
                        low_price=prev_candle['high'],
                        origin_candle_index=candle_index,
                        origin_timestamp=current_candle.name if hasattr(current_candle.name, 'timestamp') else datetime.now(),
                        strength=self._classify_pattern_strength(gap_size),
                        status=PatternStatus.ACTIVE,
                        probability=min(90.0, 50.0 + (gap_size_pips * 2)),
                        gap_size_pips=gap_size_pips,
                        narrative=f"Bullish FVG - Gap: {gap_size_pips:.1f} pips"
                    )
                    
                    return fvg
            
            return None
            
        except Exception as e:
            self._log_debug(f"Error detectando Bullish FVG: {e}")
            return None
    
    def _detect_bearish_fvg(self, candles, candle_index: int) -> Optional[FairValueGap]:
        """üìâ Detecta Bearish Fair Value Gap"""
        try:
            if candle_index < 1 or candle_index >= len(candles) - 1:
                return None
            
            prev_candle = candles.iloc[candle_index - 1]
            current_candle = candles.iloc[candle_index]
            next_candle = candles.iloc[candle_index + 1]
            
            # Condici√≥n: Gap entre high de next y low de prev
            if next_candle['high'] < prev_candle['low']:
                gap_size = prev_candle['low'] - next_candle['high']
                gap_size_pips = gap_size * 10000  # Conversi√≥n simplificada a pips
                
                if gap_size_pips >= self.min_fvg_size_pips:
                    fvg = FairValueGap(
                        fvg_type=FVGType.BEARISH_FVG,
                        high_price=prev_candle['low'],
                        low_price=next_candle['high'],
                        origin_candle_index=candle_index,
                        origin_timestamp=current_candle.name if hasattr(current_candle.name, 'timestamp') else datetime.now(),
                        strength=self._classify_pattern_strength(gap_size),
                        status=PatternStatus.ACTIVE,
                        probability=min(90.0, 50.0 + (gap_size_pips * 2)),
                        gap_size_pips=gap_size_pips,
                        narrative=f"Bearish FVG - Gap: {gap_size_pips:.1f} pips"
                    )
                    
                    return fvg
            
            return None
            
        except Exception as e:
            self._log_debug(f"Error detectando Bearish FVG: {e}")
            return None
    
    def _calculate_reaction_strength(self, candles, candle_index: int, direction: str) -> float:
        """‚ö° Calcula la fuerza de reacci√≥n desde un nivel"""
        try:
            if candle_index >= len(candles) - 3:
                return 0.0
            
            origin_candle = candles.iloc[candle_index]
            reaction_strength = 0.0
            
            # Analizar las siguientes 3-5 velas
            for i in range(candle_index + 1, min(candle_index + 6, len(candles))):
                next_candle = candles.iloc[i]
                
                if direction == 'bullish':
                    # Medir distancia desde el high del Order Block
                    distance = abs(next_candle['high'] - origin_candle['high'])
                elif direction == 'bearish':
                    # Medir distancia desde el low del Order Block
                    distance = abs(origin_candle['low'] - next_candle['low'])
                else:
                    continue
                
                reaction_strength = max(reaction_strength, distance)
            
            return reaction_strength
            
        except Exception as e:
            self._log_debug(f"Error calculando reacci√≥n: {e}")
            return 0.0
    
    def _classify_pattern_strength(self, value: float) -> PatternStrength:
        """üí™ Clasifica la fuerza del pattern"""
        try:
            # Clasificaci√≥n basada en el valor (ajustable)
            if value < 0.001:
                return PatternStrength.WEAK
            elif value < 0.002:
                return PatternStrength.MODERATE
            elif value < 0.004:
                return PatternStrength.STRONG
            else:
                return PatternStrength.VERY_STRONG
        except:
            return PatternStrength.WEAK
    
    def _validate_pattern_quality(self, patterns: List, candles) -> List:
        """üîç Valida la calidad de los patterns"""
        try:
            validated_patterns = []
            
            for pattern in patterns:
                # Validaciones b√°sicas
                if pattern.probability >= self.min_pattern_probability:
                    # Validaci√≥n adicional espec√≠fica del tipo
                    if self._validate_specific_pattern(pattern, candles):
                        validated_patterns.append(pattern)
            
            return validated_patterns
            
        except Exception as e:
            self._log_error(f"Error validando calidad: {e}")
            return patterns
    
    def _validate_specific_pattern(self, pattern, candles) -> bool:
        """üéØ Validaci√≥n espec√≠fica por tipo de pattern"""
        try:
            # Validaciones b√°sicas comunes
            if isinstance(pattern, OrderBlock):
                # Validar que el Order Block tenga sentido
                return pattern.high_price > pattern.low_price
            
            elif isinstance(pattern, FairValueGap):
                # Validar que el FVG tenga sentido
                return pattern.gap_size_pips > 0
            
            return True
            
        except Exception as e:
            self._log_debug(f"Error en validaci√≥n espec√≠fica: {e}")
            return False
    
    def _calculate_pattern_metrics(self, patterns: List, candles) -> List:
        """üìä Calcula m√©tricas avanzadas de patterns"""
        try:
            for pattern in patterns:
                # A√±adir contexto del s√≠mbolo y timeframe
                pattern.symbol = getattr(candles, 'symbol', '')
                pattern.timeframe = getattr(candles.attrs, 'timeframe', '') if hasattr(candles, 'attrs') else ''
                
                # A√±adir stats de SIC v3.1
                if self._sic:
                    pattern.sic_stats = {
                        'detected_by': 'ICTPatternDetector v6.0',
                        'sic_version': 'v3.1.0-enterprise',
                        'processing_time': time.time()
                    }
            
            return patterns
            
        except Exception as e:
            self._log_error(f"Error calculando m√©tricas: {e}")
            return patterns
    
    def _calculate_overall_quality(self, order_blocks: List[OrderBlock], fvgs: List[FairValueGap]) -> float:
        """üèÜ Calcula la calidad general de la detecci√≥n"""
        try:
            if not order_blocks and not fvgs:
                return 0.0
            
            total_patterns = len(order_blocks) + len(fvgs)
            quality_sum = 0.0
            
            # Sumar calidad de Order Blocks
            for ob in order_blocks:
                quality_sum += ob.probability
            
            # Sumar calidad de FVGs
            for fvg in fvgs:
                quality_sum += fvg.probability
            
            return quality_sum / total_patterns if total_patterns > 0 else 0.0
            
        except Exception as e:
            self._log_debug(f"Error calculando calidad general: {e}")
            return 0.0
    
    def _get_market_data(self, symbol: str, timeframe: str, lookback_days: int):
        """üì• Obtiene datos de mercado"""
        try:
            if not self._downloader:
                self._log_error("AdvancedCandleDownloader no disponible")
                return None
            
            # Calcular fechas
            end_date = datetime.now()
            start_date = end_date - timedelta(days=lookback_days)
            
            # Descargar datos
            result = self._downloader.download_candles(
                symbol=symbol,
                timeframe=timeframe,
                start_date=start_date,
                end_date=end_date,
                save_to_file=False
            )
            
            if result and result.get('success', False):
                data = result.get('data')
                if data is not None and len(data) > 0:
                    # Agregar metadatos
                    if hasattr(data, 'attrs'):
                        data.attrs['symbol'] = symbol
                        data.attrs['timeframe'] = timeframe
                    
                    self._log_info(f"‚úÖ Datos obtenidos: {len(data)} velas {symbol} {timeframe}")
                    return data
            
            self._log_warning(f"Sin datos para {symbol} {timeframe}")
            return None
            
        except Exception as e:
            self._log_error(f"Error obteniendo datos: {e}")
            return None
    
    def _create_empty_result(self, symbol: str, timeframe: str) -> PatternDetectionResult:
        """üì≠ Crea resultado vac√≠o"""
        return PatternDetectionResult(
            symbol=symbol,
            timeframe=timeframe,
            total_patterns=0,
            quality_score=0.0,
            processing_time=0.0
        )
    
    def _update_detector_state(self, result: PatternDetectionResult):
        """üìù Actualiza estado del detector"""
        try:
            with self._lock:
                # Actualizar listas principales
                self.detected_order_blocks.extend(result.order_blocks)
                self.detected_fvgs.extend(result.fair_value_gaps)
                
                # Mantener solo los m√°s recientes (√∫ltimos 100)
                self.detected_order_blocks = self.detected_order_blocks[-100:]
                self.detected_fvgs = self.detected_fvgs[-100:]
                
                # Actualizar cache
                cache_key = f"{result.symbol}_{result.timeframe}"
                self.pattern_cache[cache_key] = {
                    'timestamp': result.detection_timestamp,
                    'result': result
                }
                
        except Exception as e:
            self._log_error(f"Error actualizando estado: {e}")
    
    def _update_performance_metrics(self, result: PatternDetectionResult):
        """üìä Actualiza m√©tricas de performance"""
        try:
            metric = {
                'symbol': result.symbol,
                'timeframe': result.timeframe,
                'total_patterns': result.total_patterns,
                'quality_score': result.quality_score,
                'processing_time': result.processing_time,
                'timestamp': result.detection_timestamp
            }
            
            self.performance_metrics.append(metric)
            
            # Mantener solo las √∫ltimas 50 m√©tricas
            self.performance_metrics = self.performance_metrics[-50:]
            
        except Exception as e:
            self._log_error(f"Error actualizando m√©tricas: {e}")
    
    def get_detector_summary(self) -> Dict[str, Any]:
        """üìã Obtiene resumen del detector"""
        try:
            return {
                'total_order_blocks': len(self.detected_order_blocks),
                'total_fvgs': len(self.detected_fvgs),
                'cache_entries': len(self.pattern_cache),
                'performance_samples': len(self.performance_metrics),
                'avg_processing_time': sum(m['processing_time'] for m in self.performance_metrics) / len(self.performance_metrics) if self.performance_metrics else 0.0,
                'avg_quality_score': sum(m['quality_score'] for m in self.performance_metrics) / len(self.performance_metrics) if self.performance_metrics else 0.0,
                'sic_integration': self._sic is not None,
                'market_structure_integration': self._market_structure is not None
            }
        except Exception as e:
            self._log_error(f"Error obteniendo resumen: {e}")
            return {}
    
    def get_active_patterns(self, symbol: str = None, timeframe: str = None) -> Dict[str, List]:
        """üéØ Obtiene patterns activos"""
        try:
            active_obs = [ob for ob in self.detected_order_blocks if ob.status == PatternStatus.ACTIVE]
            active_fvgs = [fvg for fvg in self.detected_fvgs if fvg.status == PatternStatus.ACTIVE]
            
            # Filtrar por s√≠mbolo y timeframe si se especifica
            if symbol:
                active_obs = [ob for ob in active_obs if ob.symbol == symbol]
                active_fvgs = [fvg for fvg in active_fvgs if fvg.symbol == symbol]
            
            if timeframe:
                active_obs = [ob for ob in active_obs if ob.timeframe == timeframe]
                active_fvgs = [fvg for fvg in active_fvgs if fvg.timeframe == timeframe]
            
            return {
                'order_blocks': active_obs,
                'fair_value_gaps': active_fvgs,
                'total_active': len(active_obs) + len(active_fvgs)
            }
            
        except Exception as e:
            self._log_error(f"Error obteniendo patterns activos: {e}")
            return {'order_blocks': [], 'fair_value_gaps': [], 'total_active': 0}
    
    # ===============================
    # INTEGRACI√ìN MEMORIA UNIFICADA (SIC + SLUC)
    # ===============================
    
    def _update_unified_memory_with_patterns(self, 
                                           result: PatternDetectionResult, 
                                           symbol: str, 
                                           timeframe: str) -> None:
        """
        üß† Actualiza el Sistema de Memoria Unificada con los patterns detectados
        
        Integra los patterns ICT detectados con el sistema de memoria v6.0
        usando SIC + SLUC para an√°lisis contextual inteligente.
        
        Args:
            result: Resultado de la detecci√≥n de patterns
            symbol: S√≠mbolo analizado
            timeframe: Timeframe del an√°lisis
        """
        try:
            if not self._unified_memory:
                return
            
            # üìä Preparar datos para memoria unificada
            analysis_data = {
                'symbol': symbol,
                'timeframes_analyzed': [timeframe],
                'current_price': 0.0,  # Se actualizar√° con datos reales
                'market_bias': self._determine_pattern_bias(result),
                'timeframe_results': {
                    timeframe: {
                        'bias': self._determine_pattern_bias(result),
                        'strength': result.quality_score / 100.0,
                        'analysis': {
                            'total_patterns': result.total_patterns,
                            'order_blocks_count': len(result.order_blocks),
                            'fvg_count': len(result.fair_value_gaps),
                            'pattern_quality': result.quality_score,
                            'processing_time': result.processing_time
                        }
                    }
                },
                'smart_money_analysis': {
                    'institutional_bias': self._determine_institutional_bias(result),
                    'pattern_efficiency': {
                        f'{timeframe}_session': min(result.quality_score / 100.0, 1.0)
                    }
                }
            }
            
            # üîÑ Actualizar memoria usando SIC + SLUC
            update_result = update_market_memory(analysis_data)
            
            self._log_info(f"üß† Memoria unificada actualizada - Symbol: {symbol}, "
                          f"Quality: {update_result.get('memory_quality', 'N/A')}, "
                          f"Coherence: {update_result.get('coherence_score', 'N/A')}")
            
        except Exception as e:
            self._log_error(f"Error actualizando memoria unificada: {e}")
    
    def _determine_pattern_bias(self, result: PatternDetectionResult) -> str:
        """üìà Determina el bias del mercado basado en patterns detectados"""
        try:
            bullish_patterns = 0
            bearish_patterns = 0
            
            # Contar Order Blocks
            for ob in result.order_blocks:
                if ob.ob_type == OrderBlockType.BULLISH_OB:
                    bullish_patterns += 1
                elif ob.ob_type == OrderBlockType.BEARISH_OB:
                    bearish_patterns += 1
            
            # Contar Fair Value Gaps
            for fvg in result.fair_value_gaps:
                if fvg.fvg_type == FVGType.BULLISH_FVG:
                    bullish_patterns += 1
                elif fvg.fvg_type == FVGType.BEARISH_FVG:
                    bearish_patterns += 1
            
            # Determinar bias
            if bullish_patterns > bearish_patterns:
                return "BULLISH"
            elif bearish_patterns > bullish_patterns:
                return "BEARISH"
            else:
                return "NEUTRAL"
                
        except Exception:
            return "NEUTRAL"
    
    def _determine_institutional_bias(self, result: PatternDetectionResult) -> str:
        """üèõÔ∏è Determina el bias institucional basado en la calidad de patterns"""
        try:
            if result.quality_score >= 75.0:
                return self._determine_pattern_bias(result)
            elif result.quality_score >= 50.0:
                bias = self._determine_pattern_bias(result)
                return bias if bias != "NEUTRAL" else "NEUTRAL"
            else:
                return "NEUTRAL"
                
        except Exception:
            return "NEUTRAL"

    # ===============================
    # üß† M√âTODOS MEMORY-AWARE FASE 3
    # ===============================
    
    def detect_bos_with_memory(self, data=None, timeframe: str = "M15", symbol: str = "EURUSD") -> dict:
        """
        üéØ BOS Detection con memoria hist√≥rica (FASE 3)
        ‚úÖ REGLA #2: Memoria cr√≠tica aplicada
        """
        try:
            # 1. Detecci√≥n tradicional usando detect_patterns
            traditional_result = self.detect_patterns(
                symbol=symbol,
                timeframe=timeframe,
                lookback_days=3
            )
            
            # Extraer BOS info del resultado
            traditional_bos = {
                'detected': len(traditional_result.order_blocks) > 0,
                'order_blocks': traditional_result.order_blocks,
                'confidence': traditional_result.quality_score / 100.0,
                'strength': min(1.0, len(traditional_result.order_blocks) / 5.0)
            }
            
            # 2. Enhancement con memoria FASE 2
            if self._unified_memory_system and UNIFIED_MEMORY_SYSTEM_AVAILABLE:
                # Obtener contexto hist√≥rico
                historical_context = self._unified_memory_system.get_historical_insight(
                    f"BOS patterns {timeframe}", timeframe
                )
                
                # Mejorar con memoria
                enhanced_bos = self._enhance_with_memory(traditional_bos, historical_context, "BOS")
                
                # Registrar en memoria para aprendizaje futuro
                if enhanced_bos.get('detected', False):
                    self._unified_memory_system.market_context.add_bos_event({
                        'timestamp': datetime.now(),
                        'timeframe': timeframe,
                        'symbol': symbol,
                        'data': enhanced_bos,
                        'confidence': enhanced_bos.get('confidence', 0.0)
                    })
                
                self._log_info(f"üß† BOS con memoria hist√≥rica aplicada - Confianza: {enhanced_bos.get('confidence', 0):.2f}")
                return enhanced_bos
            else:
                # Fallback a detecci√≥n tradicional
                self._log_warning("üß† UnifiedMemorySystem no disponible, usando detecci√≥n tradicional")
                return traditional_bos
                
        except Exception as e:
            self._log_error(f"Error en BOS con memoria: {e}")
            return {'detected': False, 'error': str(e)}
    
    def detect_choch_with_memory(self, data=None, timeframe: str = "M15", symbol: str = "EURUSD") -> dict:
        """
        üéØ CHoCH Detection con memoria hist√≥rica (FASE 3)
        ‚úÖ REGLA #2: Memoria cr√≠tica aplicada
        """
        try:
            # 1. Detecci√≥n tradicional usando detect_patterns
            traditional_result = self.detect_patterns(
                symbol=symbol,
                timeframe=timeframe,
                lookback_days=3
            )
            
            # Extraer CHoCH info del resultado (usando FVGs como proxy)
            traditional_choch = {
                'detected': len(traditional_result.fair_value_gaps) > 0,
                'fair_value_gaps': traditional_result.fair_value_gaps,
                'confidence': traditional_result.quality_score / 100.0,
                'strength': min(1.0, len(traditional_result.fair_value_gaps) / 3.0)
            }
            
            # 2. Enhancement con memoria FASE 2
            if self._unified_memory_system and UNIFIED_MEMORY_SYSTEM_AVAILABLE:
                # Obtener contexto hist√≥rico
                historical_context = self._unified_memory_system.get_historical_insight(
                    f"CHoCH patterns {timeframe}", timeframe
                )
                
                # Mejorar con memoria
                enhanced_choch = self._enhance_with_memory(traditional_choch, historical_context, "CHoCH")
                
                # Registrar en memoria para aprendizaje futuro
                if enhanced_choch.get('detected', False):
                    self._unified_memory_system.market_context.add_choch_event({
                        'timestamp': datetime.now(),
                        'timeframe': timeframe,
                        'symbol': symbol,
                        'data': enhanced_choch,
                        'confidence': enhanced_choch.get('confidence', 0.0)
                    })
                
                self._log_info(f"üß† CHoCH con memoria hist√≥rica aplicada - Confianza: {enhanced_choch.get('confidence', 0):.2f}")
                return enhanced_choch
            else:
                # Fallback a detecci√≥n tradicional
                self._log_warning("üß† UnifiedMemorySystem no disponible, usando detecci√≥n tradicional")
                return traditional_choch
                
        except Exception as e:
            self._log_error(f"Error en CHoCH con memoria: {e}")
            return {'detected': False, 'error': str(e)}
    
    def _enhance_with_memory(self, current_detection: dict, historical_context: dict, pattern_type: str) -> dict:
        """
        üß† Mejora detecci√≥n actual con contexto hist√≥rico (FASE 3)
        ‚úÖ REGLA #2: Memoria como trader real
        """
        try:
            if not current_detection:
                return current_detection
            
            enhanced = current_detection.copy()
            
            # Ajuste de confianza basado en hist√≥rico
            if historical_context and historical_context.get('similar_patterns'):
                historical_success_rate = historical_context.get('success_rate', 0.5)
                confidence_multiplier = 0.5 + 0.5 * historical_success_rate
                
                # Aplicar multiplicador
                original_confidence = enhanced.get('confidence', 0.5)
                enhanced['confidence'] = min(1.0, original_confidence * confidence_multiplier)
                
                # Agregar informaci√≥n de memoria
                enhanced['memory_enhanced'] = True
                enhanced['historical_success_rate'] = historical_success_rate
                enhanced['confidence_adjustment'] = confidence_multiplier
            
            # Filtro de falsos positivos conocidos
            if self._is_known_false_positive(current_detection, historical_context):
                enhanced['confidence'] *= 0.3
                enhanced['warnings'] = enhanced.get('warnings', [])
                enhanced['warnings'].append("Pattern similar a falso positivo hist√≥rico")
                enhanced['false_positive_risk'] = True
            
            # Evaluaci√≥n de calidad basada en experiencia
            if self._unified_memory_system:
                quality_assessment = self._unified_memory_system.confidence_evaluator.assess_market_confidence(enhanced)
                enhanced['trader_confidence'] = quality_assessment
            
            return enhanced
            
        except Exception as e:
            self._log_error(f"Error en enhancement con memoria: {e}")
            return current_detection
    
    def _is_known_false_positive(self, current_detection: dict, historical_context: dict) -> bool:
        """
        üîç Detecta si el pattern actual es similar a falsos positivos conocidos
        """
        try:
            if not historical_context or not current_detection:
                return False
            
            # Verificar patrones fallidos hist√≥ricos
            failed_patterns = historical_context.get('failed_patterns', [])
            if not failed_patterns:
                return False
            
            # Comparar caracter√≠sticas b√°sicas
            current_confidence = current_detection.get('confidence', 0.5)
            current_strength = current_detection.get('strength', 0.5)
            
            for failed_pattern in failed_patterns:
                failed_confidence = failed_pattern.get('confidence', 0.5)
                failed_strength = failed_pattern.get('strength', 0.5)
                
                # Si confianza y fuerza son muy similares, puede ser falso positivo
                confidence_diff = abs(current_confidence - failed_confidence)
                strength_diff = abs(current_strength - failed_strength)
                
                if confidence_diff < 0.1 and strength_diff < 0.1:
                    return True
            
            return False
            
        except Exception as e:
            self._log_error(f"Error verificando falsos positivos: {e}")
            return False

    # ===============================
    # FAIR VALUE GAPS WITH MEMORY
    # ===============================
    
    def detect_fvg_with_memory(self, 
                              data=None, 
                              timeframe: str = "M15", 
                              symbol: str = "EURUSD") -> dict:
        """
        üíé FVG Detection con memoria hist√≥rica (FASE 1)
        üîÑ MIGRATED: Enhanced version of detectar_fair_value_gaps()
        ‚úÖ REGLA #2: Memoria cr√≠tica aplicada
        ‚úÖ REGLA #4: SIC/SLUC integration
        """
        
        try:
            start_time = time.time()
            self._log_info(f"üîç INICIANDO FVG detection con memoria - {symbol} {timeframe}")
            
            # 1. Preparar datos
            if data is None:
                if not self._downloader:
                    return {
                        'detected_fvgs': [],
                        'memory_enhanced': False,
                        'error': 'No downloader available'
                    }
                
                data = self._downloader.download_candles(
                    symbol=symbol,
                    timeframe=timeframe,
                    bars_count=self.pattern_lookback
                )
            
            if data is None or len(data) < 3:
                self._log_warning(f"‚ö†Ô∏è Dataset insuficiente para an√°lisis FVG: {len(data) if data is not None else 0} velas")
                return {
                    'detected_fvgs': [],
                    'memory_enhanced': False,
                    'error': 'Insufficient data'
                }
            
            # 2. Base FVG detection (MIGRATED LOGIC)
            fvg_candidates = self._detect_fair_value_gaps_enhanced(data, timeframe, symbol)
            
            # 3. Memory enhancement si est√° disponible
            enhanced_fvgs = fvg_candidates
            memory_enhanced = False
            
            if self._unified_memory_system and hasattr(self._unified_memory_system, 'enhance_fvg_detection'):
                try:
                    enhancement_result = self._unified_memory_system.enhance_fvg_detection(
                        fvg_candidates, symbol, timeframe
                    )
                    if enhancement_result:
                        enhanced_fvgs = enhancement_result.get('enhanced_fvgs', fvg_candidates)
                        memory_enhanced = True
                        self._log_info(f"üß† Memory enhancement aplicado: {len(enhanced_fvgs)} FVGs procesados")
                except Exception as e:
                    self._log_warning(f"‚ö†Ô∏è Memory enhancement fall√≥: {e}")
            
            # 4. Performance metrics
            execution_time = time.time() - start_time
            
            result = {
                'detected_fvgs': enhanced_fvgs,
                'total_detected': len(enhanced_fvgs),
                'memory_enhanced': memory_enhanced,
                'execution_time': execution_time,
                'symbol': symbol,
                'timeframe': timeframe,
                'performance_ok': execution_time < 5.0,
                'timestamp': datetime.now().isoformat()
            }
            
            self._log_info(f"‚úÖ FVG detection completado: {len(enhanced_fvgs)} FVGs en {execution_time:.2f}s")
            
            return result
            
        except Exception as e:
            self._log_error(f"‚ùå Error en FVG detection con memoria: {e}")
            return {
                'detected_fvgs': [],
                'memory_enhanced': False,
                'error': str(e),
                'execution_time': time.time() - start_time if 'start_time' in locals() else 0
            }
    
    def _detect_fair_value_gaps_enhanced(self, candles, timeframe: str, symbol: str) -> List[FairValueGap]:
        """
        üîÑ MIGRATED: Enhanced version of detectar_fair_value_gaps()
        Migra la l√≥gica completa desde proyecto principal/poi_detector.py
        """
        fvgs = []
        
        try:
            if len(candles) < 3:
                return fvgs
            
            self._log_debug(f"Escaneando {len(candles)-2} posiciones para detectar Fair Value Gaps...")
            
            bullish_fvg_count = 0
            bearish_fvg_count = 0
            
            for i in range(1, len(candles) - 1):
                prev_candle = candles.iloc[i-1]
                current_candle = candles.iloc[i]
                next_candle = candles.iloc[i+1]
                
                # BULLISH FVG: next_low > prev_high (MIGRATED LOGIC)
                if next_candle['low'] > prev_candle['high']:
                    gap_size = next_candle['low'] - prev_candle['high']
                    gap_pips = gap_size * 10000
                    
                    # MIGRATED: Usar scoring legacy
                    score = self._calcular_score_fvg_enhanced(prev_candle, current_candle, next_candle, "BULLISH")
                    confidence = self._determinar_confianza_fvg_enhanced(prev_candle, next_candle)
                    
                    # Crear FVG con estructura enterprise
                    fvg_bullish = FairValueGap(
                        fvg_type=FVGType.BULLISH_FVG,
                        high_price=next_candle['low'],
                        low_price=prev_candle['high'],
                        origin_candle_index=i,
                        origin_timestamp=current_candle.name if hasattr(current_candle.name, 'timestamp') else datetime.now(),
                        strength=self._classify_pattern_strength(gap_size),
                        status=PatternStatus.ACTIVE,
                        probability=min(90.0, score * 1.2),
                        filled_percentage=0.0,
                        is_filled=False,
                        fill_timestamp=None,
                        gap_size_pips=gap_pips,
                        volume_confirmation=False,
                        structure_confluence=False,
                        timeframe=timeframe,
                        symbol=symbol,
                        narrative=f"Bullish FVG - Gap: {gap_pips:.1f} pips | Score: {score} | Confidence: {confidence:.2f}",
                        sic_stats={
                            'legacy_score': score,
                            'legacy_confidence': confidence
                        }
                    )
                    
                    fvgs.append(fvg_bullish)
                    bullish_fvg_count += 1
                    
                    self._log_debug(f"‚úÖ BULLISH_FVG @ {fvg_bullish.get_middle_price():.5f} | Gap: {gap_pips:.1f} pips | Score: {score}")
                
                # BEARISH FVG: next_high < prev_low (MIGRATED LOGIC)
                elif next_candle['high'] < prev_candle['low']:
                    gap_size = prev_candle['low'] - next_candle['high']
                    gap_pips = gap_size * 10000
                    
                    # MIGRATED: Usar scoring legacy
                    score = self._calcular_score_fvg_enhanced(prev_candle, current_candle, next_candle, "BEARISH")
                    confidence = self._determinar_confianza_fvg_enhanced(prev_candle, next_candle)
                    
                    # Crear FVG con estructura enterprise
                    fvg_bearish = FairValueGap(
                        fvg_type=FVGType.BEARISH_FVG,
                        high_price=prev_candle['low'],
                        low_price=next_candle['high'],
                        origin_candle_index=i,
                        origin_timestamp=current_candle.name if hasattr(current_candle.name, 'timestamp') else datetime.now(),
                        strength=self._classify_pattern_strength(gap_size),
                        status=PatternStatus.ACTIVE,
                        probability=min(90.0, score * 1.2),
                        filled_percentage=0.0,
                        is_filled=False,
                        fill_timestamp=None,
                        gap_size_pips=gap_pips,
                        volume_confirmation=False,
                        structure_confluence=False,
                        timeframe=timeframe,
                        symbol=symbol,
                        narrative=f"Bearish FVG - Gap: {gap_pips:.1f} pips | Score: {score} | Confidence: {confidence:.2f}",
                        sic_stats={
                            'legacy_score': score,
                            'legacy_confidence': confidence
                        }
                    )
                    
                    fvgs.append(fvg_bearish)
                    bearish_fvg_count += 1
                    
                    self._log_debug(f"‚úÖ BEARISH_FVG @ {fvg_bearish.get_middle_price():.5f} | Gap: {gap_pips:.1f} pips | Score: {score}")
            
            self._log_info(f"üéØ DETECCI√ìN FVG COMPLETADA: {len(fvgs)} total ({bullish_fvg_count} alcistas, {bearish_fvg_count} bajistas)")
            
            return fvgs
            
        except Exception as e:
            self._log_error(f"‚ùå ERROR en detecci√≥n de Fair Value Gaps enhanced: {e}")
            return []
    
    # ===============================
    # FASE 2: MEMORY ENHANCEMENT METHODS
    # ===============================
    
    def _enhance_fvg_with_memory_v2(self, fvg: FairValueGap, historical_context: dict, market_context: dict) -> FairValueGap:
        """
        üß† FASE 2: Mejora FVG individual con memoria hist√≥rica y contexto de mercado
        ‚úÖ REGLA #2: Aplica experiencia hist√≥rica para mejorar detecci√≥n
        """
        try:
            enhanced_fvg = fvg
            
            # 1. Ajuste de probabilidad basado en contexto hist√≥rico
            if historical_context and historical_context.get('success_rate'):
                historical_success = historical_context['success_rate']
                confidence_multiplier = 0.7 + 0.3 * historical_success
                enhanced_fvg.probability = min(0.95, fvg.probability * confidence_multiplier)
            
            # 2. Evaluaci√≥n de confluence con estructura de mercado
            if market_context:
                structure_bias = market_context.get('structure_bias', 'neutral')
                fvg_direction = 'bullish' if fvg.fvg_type == FVGType.BULLISH_FVG else 'bearish'
                
                if structure_bias == fvg_direction:
                    enhanced_fvg.structure_confluence = True
                    enhanced_fvg.probability = min(0.95, enhanced_fvg.probability * 1.2)
                elif structure_bias != 'neutral' and structure_bias != fvg_direction:
                    enhanced_fvg.probability *= 0.8
            
            # 3. An√°lisis de volumen si est√° disponible
            if market_context.get('volume_analysis'):
                volume_confirmation = market_context['volume_analysis'].get('above_average', False)
                enhanced_fvg.volume_confirmation = volume_confirmation
                if volume_confirmation:
                    enhanced_fvg.probability = min(0.95, enhanced_fvg.probability * 1.1)
            
            # 4. Actualizar m√©tricas SIC
            enhanced_fvg.sic_stats.update({
                'memory_enhanced': True,
                'historical_success_rate': historical_context.get('success_rate', 0.5) if historical_context else 0.5,
                'structure_confluence': enhanced_fvg.structure_confluence,
                'fase_2_applied': True
            })
            
            return enhanced_fvg
            
        except Exception as e:
            self._log_error(f"Error en enhancement FVG con memoria: {e}")
            return fvg
    
    def _filter_fvgs_by_quality(self, fvgs: List[FairValueGap], historical_context: dict) -> List[FairValueGap]:
        """
        üîç FASE 2: Filtra FVGs basado en calidad y experiencia hist√≥rica
        ‚úÖ REGLA #2: Usa memoria para eliminar falsos positivos
        """
        try:
            if not fvgs:
                return fvgs
            
            # Par√°metros de filtrado basados en memoria
            min_probability = 0.6  # Default
            min_gap_size = 3.0     # pips
            
            if historical_context:
                # Ajustar filtros basado en experiencia hist√≥rica
                avg_success_rate = historical_context.get('success_rate', 0.6)
                if avg_success_rate > 0.8:
                    min_probability = 0.5  # Relajar filtros si hist√≥ricamente exitoso
                elif avg_success_rate < 0.4:
                    min_probability = 0.7  # Endurecer filtros si hist√≥ricamente fallido
            
            filtered_fvgs = []
            for fvg in fvgs:
                # Filtro de probabilidad
                if fvg.probability < min_probability:
                    continue
                
                # Filtro de tama√±o de gap
                if fvg.gap_size_pips < min_gap_size:
                    continue
                
                # Filtro de falsos positivos conocidos
                if self._is_known_false_positive_fvg(fvg, historical_context):
                    continue
                
                filtered_fvgs.append(fvg)
            
            self._log_debug(f"üîç FVGs filtrados: {len(fvgs)} ‚Üí {len(filtered_fvgs)} (quality threshold: {min_probability})")
            return filtered_fvgs
            
        except Exception as e:
            self._log_error(f"Error en filtrado de FVGs: {e}")
            return fvgs
    
    def _apply_fvg_confluence_analysis(self, fvgs: List[FairValueGap], market_context: dict) -> List[FairValueGap]:
        """
        üéØ FASE 2: Aplica an√°lisis de confluence entre FVGs y otros patterns
        ‚úÖ REGLA #2: Mejora detecci√≥n mediante confluence con OBs, estructura, etc.
        """
        try:
            if not fvgs or not market_context:
                return fvgs
            
            confluence_fvgs = []
            
            for fvg in fvgs:
                confluence_score = 0
                confluence_factors = []
                
                # 1. Confluence con Order Blocks
                nearby_obs = market_context.get('nearby_order_blocks', [])
                for ob in nearby_obs:
                    distance = abs(fvg.get_middle_price() - ob.get('middle_price', 0))
                    if distance < 50 * 0.0001:  # ~50 pips
                        confluence_score += 1
                        confluence_factors.append('order_block_proximity')
                
                # 2. Confluence con niveles de estructura
                structure_levels = market_context.get('structure_levels', [])
                for level in structure_levels:
                    distance = abs(fvg.get_middle_price() - level.get('price', 0))
                    if distance < 20 * 0.0001:  # ~20 pips
                        confluence_score += 1
                        confluence_factors.append('structure_level')
                
                # 3. Confluence con trend direction
                trend_direction = market_context.get('trend_direction', 'neutral')
                fvg_direction = 'bullish' if fvg.fvg_type == FVGType.BULLISH_FVG else 'bearish'
                
                if trend_direction == fvg_direction:
                    confluence_score += 1
                    confluence_factors.append('trend_alignment')
                
                # 4. Aplicar confluence score
                if confluence_score > 0:
                    confluence_multiplier = 1.0 + (confluence_score * 0.1)
                    fvg.probability = min(0.95, fvg.probability * confluence_multiplier)
                    fvg.structure_confluence = confluence_score >= 2
                    
                    # Actualizar SIC stats
                    fvg.sic_stats.update({
                        'confluence_score': confluence_score,
                        'confluence_factors': confluence_factors
                    })
                
                confluence_fvgs.append(fvg)
            
            self._log_debug(f"üéØ Confluence analysis aplicado a {len(fvgs)} FVGs")
            return confluence_fvgs
            
        except Exception as e:
            self._log_error(f"Error en confluence analysis: {e}")
            return fvgs
    
    def _is_known_false_positive_fvg(self, fvg: FairValueGap, historical_context: dict) -> bool:
        """
        üö´ FASE 2: Detecta si el FVG es similar a falsos positivos hist√≥ricos
        ‚úÖ REGLA #2: Usa memoria para evitar errores repetitivos
        """
        try:
            if not historical_context:
                return False
            
            failed_patterns = historical_context.get('failed_patterns', [])
            
            for failed_pattern in failed_patterns:
                # Comparar caracter√≠sticas similares
                gap_size_similar = abs(fvg.gap_size_pips - failed_pattern.get('gap_size_pips', 0)) < 5
                probability_similar = abs(fvg.probability - failed_pattern.get('probability', 0)) < 0.2
                same_type = str(fvg.fvg_type.value) == failed_pattern.get('fvg_type', '')
                
                if gap_size_similar and probability_similar and same_type:
                    self._log_debug(f"üö´ FVG similar a falso positivo hist√≥rico detectado")
                    return True
            
            return False
            
        except Exception as e:
            self._log_error(f"Error en detecci√≥n de falsos positivos: {e}")
            return False
    
    def _calcular_score_fvg_enhanced(self, prev_candle, current_candle, next_candle, direction):
        """üîÑ MIGRATED: Calcula score espec√≠fico para Fair Value Gaps desde legacy"""
        base_score = 55
        
        # Size del gap
        if direction == "BULLISH":
            gap_size = next_candle['low'] - prev_candle['high']
        else:
            gap_size = prev_candle['low'] - next_candle['high']
        
        # Normalizar gap size a pips
        gap_pips = gap_size * 10000
        gap_bonus = min(gap_pips * 2, 25)  # Max 25 puntos bonus
        
        return int(base_score + gap_bonus)
    
    def _determinar_confianza_fvg_enhanced(self, prev_candle, next_candle):
        """üîÑ MIGRATED: Determina confianza del Fair Value Gap desde legacy"""
        # Mayor confianza para gaps m√°s grandes
        gap_size = abs(next_candle['low'] - prev_candle['high']) if next_candle['low'] > prev_candle['high'] else abs(prev_candle['low'] - next_candle['high'])
        gap_pips = gap_size * 10000
        
        confidence = 0.4 + min(gap_pips * 0.05, 0.4)  # 0.4 a 0.8
        return min(confidence, 0.9)

    # ===============================
    # FASE 3: CONTEXT-AWARE DETECTION  
    # ===============================
    
    def _validate_fvg_multi_timeframe(self, 
                                    fvgs: List[FairValueGap], 
                                    symbol: str) -> List[FairValueGap]:
        """
        üìä FASE 3: Multi-timeframe FVG validation H4‚ÜíM15‚ÜíM5 seg√∫n ICT methodology
        ‚úÖ REGLA #2: Memory integration obligatoria
        ‚úÖ REGLA #4: SLUC logging estructurado
        
        Args:
            fvgs: Lista de FVG candidates
            symbol: Par de divisas
            
        Returns:
            Lista de FVGs validados por hierarchy multi-timeframe
        """
        try:
            # ‚úÖ REGLA #4: SLUC logging obligatorio
            log_trading_decision_smart_v6("FVG_MULTIFRAME_START", {
                "symbol": symbol,
                "fvg_candidates": len(fvgs),
                "methodology": "ICT_H4_M15_M5_hierarchy"
            })
            
            validated_fvgs = []
            
            for fvg in fvgs:
                # 1. H4 authority confirmation (institutional structure)
                h4_confluence = self._check_h4_fvg_confluence(fvg, symbol)
                
                # 2. M15 structure alignment (intermediate validation)
                m15_alignment = self._check_m15_structure_alignment(fvg, symbol)
                
                # 3. M5 timing precision (entry refinement)
                m5_timing = self._check_m5_timing_precision(fvg, symbol)
                
                # 4. Institutional vs Retail classification
                fvg_classification = self._classify_fvg_institutional(fvg)
                
                # ‚úÖ REGLA #2: Memory integration obligatoria
                memory_context = None
                if self._unified_memory_system:
                    try:
                        memory_context = self._unified_memory_system.get_fvg_historical_context(symbol, fvg)
                    except Exception as e:
                        self._log_warning(f"Memory context retrieval failed: {e}")
                
                # Validaci√≥n hierarchy: H4 authority + M15 structure required
                if h4_confluence and m15_alignment:
                    fvg.structure_confluence = True
                    fvg.institutional_classification = fvg_classification
                    fvg.memory_enhanced = True
                    fvg.h4_confluence = h4_confluence
                    fvg.m15_alignment = m15_alignment
                    fvg.m5_timing = m5_timing
                    
                    # Enhanced narrative con hierarchy
                    fvg.narrative = (f"{fvg.narrative} + H4 confluence + M15 structure validated"
                                   f" + {fvg_classification} classification")
                    
                    validated_fvgs.append(fvg)
                    
                    self._log_debug(f"‚úÖ FVG validated: {fvg.get_middle_price():.5f} | "
                                  f"H4: {h4_confluence} | M15: {m15_alignment} | Class: {fvg_classification}")
                else:
                    self._log_debug(f"‚ùå FVG filtered: {fvg.get_middle_price():.5f} | "
                                  f"H4: {h4_confluence} | M15: {m15_alignment}")
            
            # ‚úÖ REGLA #4: SLUC success logging
            log_trading_decision_smart_v6("FVG_MULTIFRAME_COMPLETE", {
                "validated_fvgs": len(validated_fvgs),
                "success_rate": len(validated_fvgs) / len(fvgs) if fvgs else 0,
                "institutional_count": sum(1 for fvg in validated_fvgs 
                                         if fvg.institutional_classification == 'institutional'),
                "performance": "enterprise_compliant"
            })
            
            return validated_fvgs
            
        except Exception as e:
            self._log_error(f"‚ùå Error en validaci√≥n multi-timeframe FVG: {e}")
            return fvgs  # Return original list on error
    
    def _check_h4_fvg_confluence(self, fvg: FairValueGap, symbol: str) -> bool:
        """
        üèóÔ∏è H4 authority confirmation - major structure validation
        """
        try:
            # Mock implementation - en producci√≥n usar√≠a datos H4 reales
            # Criteria: FVG debe estar cerca de estructura significativa H4
            
            # Si gap size > 20 pips = probable institutional FVG = H4 confluence
            if fvg.gap_size_pips >= 20:
                return True
                
            # Check if FVG aligns with potential H4 structure levels
            # (En implementaci√≥n real: descargar H4 data y analizar estructura)
            middle_price = fvg.get_middle_price()
            
            # Simple heuristic: precios terminados en .00 o .50 suelen ser niveles H4
            price_digits = f"{middle_price:.4f}"
            if price_digits.endswith('00') or price_digits.endswith('50'):
                return True
                
            return False
            
        except Exception as e:
            self._log_error(f"Error en H4 confluence check: {e}")
            return False
    
    def _check_m15_structure_alignment(self, fvg: FairValueGap, symbol: str) -> bool:
        """
        üìä M15 structure alignment - intermediate validation
        """
        try:
            # Mock implementation - en producci√≥n usar√≠a MarketStructureAnalyzerV6
            
            # Criteria: FVG debe alinearse con trend/structure M15
            fvg_direction = 'bullish' if fvg.fvg_type == FVGType.BULLISH_FVG else 'bearish'
            
            # Simple validation: FVGs con buena probabilidad = M15 alignment
            if fvg.probability >= 70.0:
                return True
                
            # Gap size validation: medianos/grandes m√°s probables de ser M15 valid
            if fvg.gap_size_pips >= 12.0:
                return True
                
            return False
            
        except Exception as e:
            self._log_error(f"Error en M15 structure alignment: {e}")
            return False
    
    def _check_m5_timing_precision(self, fvg: FairValueGap, symbol: str) -> bool:
        """
        ‚è∞ M5 timing precision - entry refinement
        """
        try:
            # Mock implementation - en producci√≥n analizar√≠a M5 timing
            
            # M5 timing siempre true en este mock (refinement step)
            # En producci√≥n: verificar√≠a momentum, volume, session timing
            return True
            
        except Exception as e:
            self._log_error(f"Error en M5 timing precision: {e}")
            return True  # Default to true for timing
    
    def _classify_fvg_institutional(self, fvg: FairValueGap) -> str:
        """
        üèõÔ∏è Classifica FVG como institutional vs retail
        
        Criterios ICT:
        - Institutional: Gap > 20 pips, strong probability, structure alignment
        - Retail: Gap < 20 pips, weaker signals, noise-like
        """
        try:
            # Primary classification: gap size
            if fvg.gap_size_pips >= 20:
                return "institutional"
            
            # Secondary criteria: probability + gap combination
            if fvg.gap_size_pips >= 15 and fvg.probability >= 80:
                return "institutional"
                
            # Default to retail for smaller/weaker FVGs
            return "retail"
            
        except Exception as e:
            self._log_error(f"Error en clasificaci√≥n institucional: {e}")
            return "retail"  # Default to retail on error

    # ===============================
    # M√âTODOS DE LOGGING
    # ===============================
    
    # ===============================
    # M√âTODOS DE LOGGING
    # ===============================
    
    def _log_info(self, message: str):
        """‚ÑπÔ∏è Log de informaci√≥n"""
        enviar_senal_log("INFO", f"[ICTPatternDetector v6.0] {message}", __name__, "pattern_detector")
    
    def _log_warning(self, message: str):
        """‚ö†Ô∏è Log de advertencia"""
        enviar_senal_log("WARNING", f"[ICTPatternDetector v6.0] {message}", __name__, "pattern_detector")
    
    def _log_error(self, message: str):
        """‚ùå Log de error"""
        enviar_senal_log("ERROR", f"[ICTPatternDetector v6.0] {message}", __name__, "pattern_detector")
    
    def _log_debug(self, message: str):
        """üêõ Log de debug"""
        enviar_senal_log("DEBUG", f"[ICTPatternDetector v6.0] {message}", __name__, "pattern_detector")

    # ===============================
    # ORDER BLOCKS UNIFIED METHOD
    # ===============================
    
    def detect_order_blocks_unified(self, 
                                   data, 
                                   timeframe: str, 
                                   symbol: str) -> Dict[str, Any]:
        """
        üì¶ ORDER BLOCKS ENTERPRISE - IMPLEMENTACI√ìN UNIFICADA
        ===================================================
        
        M√©todo unificado que combina todas las implementaciones:
        ‚úÖ Base: ICTPatternDetector (robustez)
        ‚úÖ Enterprise: MarketStructureAnalyzerV6 (performance)
        ‚úÖ Memory: UnifiedMemorySystem (FASE 2 completada)
        ‚úÖ Logging: SLUC v2.1 (structured logging)
        ‚úÖ Dashboard: POI widgets pattern
        
        Args:
            data: DataFrame con datos OHLCV
            timeframe: Timeframe de an√°lisis (M15, H1, etc.)
            symbol: S√≠mbolo a analizar (EURUSD, etc.)
            
        Returns:
            Dict con Order Blocks detectados y metadatos enterprise
        """
        start_time = time.time()
        
        try:
            self._log_info(f"üì¶ Iniciando Order Blocks Unified: {symbol} {timeframe}")
            
            # ============================================
            # 1. MEMORY CONTEXT (REGLA #2 - Memoria cr√≠tica)
            # ============================================
            memory_context = {}
            memory_enhanced = False
            
            if self._unified_memory_system is not None:
                try:
                    # Mock method - en el futuro se implementar√° en UnifiedMemorySystem
                    memory_context = {
                        'historical_analysis': {
                            'order_blocks_success_rate': 0.75
                        },
                        'market_state': 'trending',
                        'volatility': 'medium'
                    }
                    memory_enhanced = True
                    self._log_info(f"üß† Memory context obtenido: {len(memory_context)} elementos")
                except Exception as e:
                    self._log_warning(f"Memory context no disponible: {e}")
            
            # ============================================
            # 2. UNIFIED DETECTION ALGORITHM (H√≠brido)
            # ============================================
            
            # 2.1 Validar datos de entrada
            if data is None or len(data) < 20:
                return {
                    'blocks': [],
                    'total_blocks': 0,
                    'memory_enhanced': memory_enhanced,
                    'performance_ms': (time.time() - start_time) * 1000,
                    'sluc_logged': True,
                    'error': 'Datos insuficientes',
                    'symbol': symbol,
                    'timeframe': timeframe
                }
            
            # 2.2 Detecci√≥n base usando metodolog√≠a ICT
            order_blocks_base = self._detect_order_blocks(data)
            
            # 2.3 Enterprise enhancement usando MarketStructureV6
            enhanced_blocks = []
            
            if self._market_structure and hasattr(self._market_structure, '_detect_order_blocks_v6'):
                try:
                    # Llamar m√©todo enterprise V6
                    v6_enhancement = self._market_structure._detect_order_blocks_v6(data)
                    
                    # Combinar resultados base + enterprise
                    for base_block in order_blocks_base:
                        enhanced_block = self._apply_enterprise_enhancement(
                            base_block, 
                            memory_context, 
                            v6_enhancement
                        )
                        enhanced_blocks.append(enhanced_block)
                        
                except Exception as e:
                    self._log_warning(f"Enterprise enhancement fall√≥: {e}")
                    enhanced_blocks = order_blocks_base
            else:
                enhanced_blocks = order_blocks_base
            
            # ============================================
            # 3. MEMORY STORAGE (Patr√≥n probado FASE 2)
            # ============================================
            
            if self._unified_memory_system is not None and enhanced_blocks:
                try:
                    # Mock storage method - en el futuro se implementar√° en UnifiedMemorySystem
                    # self._unified_memory_system.store_order_blocks_analysis(...)
                    self._log_info(f"üíæ Order Blocks almacenados en memoria: {len(enhanced_blocks)}")
                except Exception as e:
                    self._log_warning(f"Error almacenando en memoria: {e}")
            
            # ============================================
            # 4. SLUC LOGGING (REGLA #4 - SIC/SLUC obligatorio)
            # ============================================
            
            performance_ms = (time.time() - start_time) * 1000
            
            try:
                from sistema.sistema_sic_real import enviar_senal_log
                enviar_senal_log(
                    "INFO",
                    f"üì¶ ORDER_BLOCKS_UNIFIED_DETECTION {symbol}: " +
                    f'{{"blocks": {len(enhanced_blocks)}, "performance_ms": {performance_ms:.2f}, ' +
                    f'"memory_enhanced": {memory_enhanced}, "timeframe": "{timeframe}"}}',
                    "pattern_detector",
                    "order_blocks"
                )
                sluc_logged = True
            except ImportError:
                self._log_info(f"üì¶ Order Blocks detectados: {len(enhanced_blocks)} en {performance_ms:.2f}ms")
                sluc_logged = False
            
            # ============================================
            # 5. RESULTADO ENTERPRISE UNIFICADO
            # ============================================
            
            result = {
                'blocks': [self._order_block_to_dict(block) for block in enhanced_blocks],
                'total_blocks': len(enhanced_blocks),
                'memory_enhanced': memory_enhanced,
                'performance_ms': performance_ms,
                'sluc_logged': sluc_logged,
                'symbol': symbol,
                'timeframe': timeframe,
                'detection_timestamp': datetime.now().isoformat(),
                'algorithm': 'unified_enterprise',
                'quality_metrics': {
                    'meets_performance_target': performance_ms < 50,
                    'memory_integration': memory_enhanced,
                    'enterprise_features': True,
                    'sluc_compliance': sluc_logged
                }
            }
            
            # Log resultado final
            self._log_info(f"‚úÖ Order Blocks Unified completado: {len(enhanced_blocks)} blocks en {performance_ms:.2f}ms")
            
            return result
            
        except Exception as e:
            self._log_error(f"‚ùå Error en Order Blocks Unified: {e}")
            
            return {
                'blocks': [],
                'total_blocks': 0,
                'memory_enhanced': False,
                'performance_ms': (time.time() - start_time) * 1000,
                'sluc_logged': False,
                'error': str(e),
                'symbol': symbol,
                'timeframe': timeframe
            }
    
    def _apply_enterprise_enhancement(self, 
                                    base_block: OrderBlock, 
                                    memory_context: Dict, 
                                    v6_enhancement: Any) -> OrderBlock:
        """
        üöÄ Aplica features enterprise al Order Block base
        
        Args:
            base_block: Order Block base detectado
            memory_context: Contexto de memoria trader
            v6_enhancement: Enhancement del MarketStructureV6
            
        Returns:
            Order Block mejorado con features enterprise
        """
        try:
            # Aplicar memory enhancement
            memory_confidence_boost = 0.0
            if memory_context and 'historical_analysis' in memory_context:
                historical = memory_context['historical_analysis']
                if historical.get('order_blocks_success_rate', 0) > 0.7:
                    memory_confidence_boost = 10.0
            
            # Aplicar enterprise features
            enhanced_probability = min(95.0, base_block.probability + memory_confidence_boost)
            
            # Crear Order Block mejorado
            enhanced_block = OrderBlock(
                ob_type=base_block.ob_type,
                high_price=base_block.high_price,
                low_price=base_block.low_price,
                origin_candle_index=base_block.origin_candle_index,
                origin_timestamp=base_block.origin_timestamp,
                strength=base_block.strength,
                status=base_block.status,
                probability=enhanced_probability,
                reaction_strength=base_block.reaction_strength,
                narrative=f"{base_block.narrative} | Memory Enhanced: +{memory_confidence_boost:.1f}%"
            )
            
            return enhanced_block
            
        except Exception as e:
            self._log_warning(f"Error en enterprise enhancement: {e}")
            return base_block
    
    def _order_block_to_dict(self, order_block: OrderBlock) -> Dict[str, Any]:
        """
        üìä Convierte Order Block a diccionario para serializaci√≥n
        
        Args:
            order_block: Order Block a convertir
            
        Returns:
            Diccionario con datos del Order Block
        """
        try:
            return {
                'type': order_block.ob_type.value if hasattr(order_block.ob_type, 'value') else str(order_block.ob_type),
                'high_price': float(order_block.high_price),
                'low_price': float(order_block.low_price),
                'origin_candle_index': int(order_block.origin_candle_index),
                'origin_timestamp': order_block.origin_timestamp.isoformat() if hasattr(order_block.origin_timestamp, 'isoformat') else str(order_block.origin_timestamp),
                'strength': order_block.strength.value if hasattr(order_block.strength, 'value') else str(order_block.strength),
                'status': order_block.status.value if hasattr(order_block.status, 'value') else str(order_block.status),
                'probability': float(order_block.probability),
                'reaction_strength': float(order_block.reaction_strength),
                'narrative': str(order_block.narrative)
            }
        except Exception as e:
            self._log_warning(f"Error convirtiendo Order Block a dict: {e}")
            return {
                'type': 'unknown',
                'error': str(e)
            }


# ===============================
# FACTORY FUNCTIONS
# ===============================

def get_pattern_detector(config: Optional[Dict[str, Any]] = None) -> ICTPatternDetector:
    """
    üè≠ Factory function para crear ICTPatternDetector v6.0
    
    Args:
        config: Configuraci√≥n opcional del detector
        
    Returns:
        Instancia configurada de ICTPatternDetector
    """
    default_config = {
        'enable_debug': True,
        'use_multi_timeframe': True,
        'enable_cache': True,
        'min_ob_reaction_pips': 10.0,
        'min_fvg_size_pips': 5.0,
        'pattern_lookback': 100,
        'min_pattern_probability': 60.0,
        'volume_weight': 0.3,
        'structure_weight': 0.7
    }
    
    if config:
        default_config.update(config)
    
    return ICTPatternDetector(config=default_config)


if __name__ == "__main__":
    print("üß™ Testing ICTPatternDetector v6.0 Enterprise...")
    
    try:
        # Crear detector con configuraci√≥n de test
        test_config = {
            'enable_debug': True,
            'use_multi_timeframe': False,  # Simplificar para test
            'min_pattern_probability': 50.0,  # Menor threshold para test
            'min_ob_reaction_pips': 5.0,
            'min_fvg_size_pips': 3.0
        }
        
        detector = get_pattern_detector(test_config)
        print("‚úÖ ICTPatternDetector creado exitosamente")
        
        # Test de detecci√≥n b√°sica
        result = detector.detect_patterns(
            symbol="EURUSD",
            timeframe="H1",
            lookback_days=3
        )
        
        print(f"‚úÖ Detecci√≥n completada: {result.total_patterns} patterns detectados")
        print(f"   - Order Blocks: {len(result.order_blocks)}")
        print(f"   - Fair Value Gaps: {len(result.fair_value_gaps)}")
        print(f"   - Calidad: {result.quality_score:.1f}%")
        print(f"   - Tiempo: {result.processing_time:.3f}s")
        
        # Test de resumen
        summary = detector.get_detector_summary()
        print(f"‚úÖ Resumen del detector: {summary}")
        
        # Test de patterns activos
        active = detector.get_active_patterns()
        print(f"‚úÖ Patterns activos: {active['total_active']}")
        
        print("üéØ Test de ICTPatternDetector v6.0 completado exitosamente")
        
    except Exception as e:
        print(f"‚ùå Error en test: {e}")
        import traceback
        traceback.print_exc()
